{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e48d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, TimeDistributed, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import backend as K \n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f59aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention layer class that is later used when building our model.\n",
    "# Source: https://arxiv.org/pdf/1409.0473.pdf\n",
    "# Source: https://colab.research.google.com/drive/1XrjPL3O_szhahYZW0z9yhCl9qvIcJJYW \n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    " \n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    " \n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    " \n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    " \n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    " \n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
    " \n",
    "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    " \n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    " \n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
    "            if verbose:\n",
    "                print('wa.s>',W_a_dot_s.shape)\n",
    " \n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>',U_a_dot_h.shape)\n",
    " \n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
    " \n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    " \n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    " \n",
    "            return e_i, [e_i]\n",
    " \n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    " \n",
    "        def create_inital_state(inputs, hidden_size):\n",
    "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
    "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
    "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
    "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
    "            return fake_state\n",
    " \n",
    "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
    "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
    " \n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    " \n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    " \n",
    "        return c_outputs, e_outputs\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brings dataset file and shapes dataset to only have information we want and need\n",
    "\n",
    "wikimoviefile = 'wiki_titles.csv'\n",
    "orgdatafile = pd.read_csv(wikimoviefile)\n",
    "num_samples = 1000\n",
    "datafile = orgdatafile.dropna(subset=['Plot','Titles'], axis=0).reset_index(drop=True) \n",
    "datafile = datafile.drop(labels=range(num_samples, 21710), axis=0)\n",
    "\n",
    "print('Data shape is ', datafile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6174e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps contractions to their actual words to help with consistency when tokenizing words\n",
    "\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that cleans text and splits them into a list of strings\n",
    "\n",
    "def text_cleaner(text):\n",
    "    # Converts all text to string\n",
    "    newString = str(text)\n",
    "    # Makes all of the string lowercased\n",
    "    newString = newString.lower()\n",
    "    # Gets rid of special characters\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    # Gets rid of quotations\n",
    "    newString = re.sub('\"','', newString)\n",
    "    # Replaces contractions to their corresponding words from the contraction map \n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])  \n",
    "    # Gets rid of /n\n",
    "    newString = re.sub(r\"'s\\n\",\"\",newString)\n",
    "    # Gets rid of more special characters\n",
    "    newString = re.sub(r'[?$()_\\-—\\d{}/#&%<>=@\\*~:;\\\\\\+\\']',r' ', newString) \n",
    "    # Make sure punctuations are separated so they can be their own tokens\n",
    "    newString = re.sub(r'([,.!;:?])', r' \\1 ', newString)\n",
    "\n",
    "    return newString.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eabde67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually cleans data in \"Plot\" and \"Titles\" and puts them in clean_data\n",
    "\n",
    "clean_data = pd.DataFrame()\n",
    "\n",
    "clean_data['plots'] = datafile['Plot'].apply(text_cleaner)\n",
    "for plot in clean_data['plots']:\n",
    "    del plot[150:]\n",
    "    \n",
    "print(clean_data['plots'])\n",
    "\n",
    "clean_data['titles'] = datafile['Titles'].apply(text_cleaner)\n",
    "\n",
    "print(clean_data['titles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddf0533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find what the maximum number of words are for title and plot to help create padding and dimensions for model\n",
    "\n",
    "max_words = 0\n",
    "for text in clean_data['plots']:\n",
    "    max_words = max(max_words, len(text))\n",
    "print(max_words)\n",
    "\n",
    "\n",
    "max_words =0\n",
    "for text in clean_data['titles']:\n",
    "    max_words = max(max_words, len(text))\n",
    "print(max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fbb386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build word embedding index using pre-trained word embedding file\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that tokenizes words, pads sequences, and creates an embedding matrix\n",
    "\n",
    "def doc2seq(texts, MAX_SEQUENCE_LENGTH, EMBEDDING_DIM):\n",
    "    # Tokenizes words except for the characters in filters \n",
    "    tokenizer = Tokenizer(filters='\"#$%&()*+-/<=>@[\\\\]^_`{|}~\\t\\n')\n",
    "    # Creates vocabulary index based on word frequency from texts\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    # Transforms text into sequence of integers\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    # Maps words to index\n",
    "    word_index = tokenizer.word_index\n",
    "    # Maps index to word\n",
    "    index_word = tokenizer.index_word\n",
    "\n",
    "    # Pads data based on its sequences and length after the sequence   \n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding = 'post')\n",
    "    \n",
    "    # Creates an embedding matrix based on embedding_index and word_index\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return data, embedding_matrix, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de10b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PLOT_LENGTH = 150\n",
    "EMBEDDING_DIM = 300\n",
    "data = clean_data.plots\n",
    "\n",
    "x_data, encoder_emb, x_word_index, x_index_word = doc2seq(data, MAX_PLOT_LENGTH, EMBEDDING_DIM)\n",
    "\n",
    "MAX_TITLE_LENGTH = 10\n",
    "EMBEDDING_DIM = 300\n",
    "data = clean_data.titles\n",
    "\n",
    "y_data, decoder_emb, y_word_index, y_index_word = doc2seq(data, MAX_TITLE_LENGTH, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b19ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits data for training and testing\n",
    "\n",
    "x_train, x_test_temp, y_train, y_test_temp = train_test_split(x_data, y_data, \n",
    "                                                            test_size=0.3, random_state=0) \n",
    "x_dev, x_test, y_dev, y_test = train_test_split(x_test_temp, y_test_temp, \n",
    "                                                            test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1cad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0107adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoding and decoding embedding layer\n",
    "\n",
    "enc_embedding_layer = Embedding(len(x_word_index) + 1, # Input dimension \n",
    "                            EMBEDDING_DIM, # Output dimension\n",
    "                            weights=[encoder_emb], #initialize weights with encoder embedding matrix\n",
    "                            input_length=MAX_PLOT_LENGTH, #length of input sequence\n",
    "                            trainable=False, # Does not update weights during training\n",
    "                            name='EncoderEmbeddingLayer')\n",
    "\n",
    "\n",
    "dec_embedding_layer = Embedding(len(y_word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[decoder_emb],\n",
    "                            input_length=MAX_TITLE_LENGTH,\n",
    "                            trainable=False,\n",
    "                            name='DecoderEmbeddingLayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221066ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word level Seq2seq model with encoder and decoder architecture\n",
    "\n",
    "# Encoder:\n",
    "# Creates encoder input and feeds it into the encoder embedding layer\n",
    "encoder_inputs = Input(shape=(MAX_PLOT_LENGTH,), name=\"EncoderInput\") #Input length is set because all input data has been padded in preprocessing\n",
    "enc_emb = enc_embedding_layer(encoder_inputs) \n",
    "\n",
    "# Creates multiple LSTM layers \n",
    "encoder_lstm1 = LSTM(hidden_units,return_sequences=True,return_state=True, name='EncLSTM1') \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "encoder_lstm2 = LSTM(hidden_units,return_sequences=True,return_state=True, name='EncLSTM2') \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "encoder_lstm3=LSTM(hidden_units, return_state=True, return_sequences=True, name='EncLSTM3') \n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a623da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder:\n",
    "decoder_inputs = Input(shape=(None,), name = 'DecoderInput') \n",
    "dec_emb = dec_embedding_layer(decoder_inputs) \n",
    "\n",
    "# LSTM uses last LSTM layer of encoder as initial state for decoder LSTM\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True, name='DecLSTM1') \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb, initial_state=[state_h, state_c]) \n",
    "\n",
    "# Create attention layer with [encoder_outputs, decoder_outputs] as input\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "# Concatenate decoder's LSTM output and attention output to return a single tensor \n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# Time Distrubted Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(len(y_word_index)+1, activation='softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_concat_input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de138a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d7f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train model\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# TensorBoard tracks loss and accuracy as our model trains\n",
    "# Tracking validation loss is useful to spot overfitting but accuracy is not useful in our case because of NLP\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "history=model.fit([x_train,np.hstack((np.zeros((y_train.shape[0],1)), y_train[:, :-1]))], \n",
    "                  y_train,\n",
    "                  epochs=19,\n",
    "                  batch_size= 9, \n",
    "                  callbacks=[tensorboard],\n",
    "                  validation_data=([x_dev,np.hstack((np.zeros((y_dev.shape[0],1)), y_dev[:, :-1]))], y_dev)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20439243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots our training and validation loss\n",
    "\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate model into encoder and decoder inference model to predict and generate movie titles\n",
    "\n",
    "# Encoder inference\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder inference\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(hidden_units,))\n",
    "decoder_state_input_c = Input(shape=(hidden_units,))\n",
    "decoder_hidden_state_input = Input(shape=(MAX_PLOT_LENGTH,hidden_units))\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# Create attention layer inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# Create dense softmax layer from model to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "\n",
    "# Creating the decoder model\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000fc292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes tokens of title words and creates a string of words from y_index_word\n",
    "def seq2title(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if(i != 0):\n",
    "            newString = newString + y_index_word[i] + ' '\n",
    "    return newString\n",
    "\n",
    "# Takes tokens of plot words and creates a string of words from x_index_word\n",
    "def seq2plot(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if(i != 0):\n",
    "            newString = newString + x_index_word[i] + ' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that takes an input and predicts what our model will output using our encoder and decoder model\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Make empty target sequence of length 1\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Start the sequence with nothing\n",
    "    target_seq[0, 0] = 0.0\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = y_index_word.get(sampled_token_index, '.')\n",
    "\n",
    "        decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Change stop condition if it reaches max title limit\n",
    "        if (len(decoded_sentence.split()) >= (MAX_TITLE_LENGTH-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb953c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates numerical measurement for the comprehension of an individual title\n",
    "# BLEU score, unigram (word by word)\n",
    "\n",
    "def calc_indiv_BLEU(id_text, text_df, title_df): \n",
    "    # Generates decoded title from plot\n",
    "    gen_output = decode_sequence(text_df[id_text].reshape(1,-1))\n",
    "    # Splits output into individual words\n",
    "    split_output = gen_output.split(\" \")\n",
    "    # Removes empty spaces and periods \n",
    "    candidate = [item for item in split_output if (item!=\".\" and item!=\"\")] \n",
    "    # Get the real title for corresponding plot\n",
    "    gen_ref = seq2title(title_df[id_text])\n",
    "    # Splits real title into the individual words\n",
    "    split_ref = gen_ref.split(\" \")\n",
    "    # Removes empty spaces and periods\n",
    "    reference = [item for item in split_ref if (item!=\".\" and item!=\"\")] \n",
    "    # Calculate + return BLEU score by comparing output and reference using sentence_bleu\n",
    "    score = sentence_bleu(gen_ref, gen_output, weights=(1, 0, 0, 0))\n",
    "\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates predictions using decode_sequence method\n",
    "\n",
    "for i in range(45,55):\n",
    "    print(\"BLEU score(Unigram): \" + str(calc_indiv_BLEU(i, x_test, y_test)))\n",
    "    print(\"Plot: \" + seq2plot(x_test[i]))\n",
    "    print(\"Original Title: \"+ seq2title(y_test[i]))\n",
    "    # We want to reshape the data so that it matches the shape to feed into our encoder model\n",
    "    print(\"Generated Title: \"+ decode_sequence(x_test[i].reshape(1,-1)))\n",
    "    print('___________________________________________________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd0ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
